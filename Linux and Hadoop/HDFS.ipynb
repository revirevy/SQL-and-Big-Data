{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# HDFS \n",
    "`storing`\n",
    "\n",
    "Files stored in HDFS are not visisble to host's file system. Have to use a special utility (e.g., hadoop fs or a web-based utility) to view files in HDFS.\n",
    "\n",
    "Optimized for millions of large files (likely over 100 mb)  \n",
    "Hierarchical directory storage  \n",
    "\n",
    "**Differences between Hadoop and Linux**  \n",
    "No current directory  \n",
    "CANNOT modify files once they are written  \n",
    "Have to use a special utility to access files\n",
    "\n",
    "---\n",
    "\n",
    "#### HDFS Structure\n",
    "\n",
    "NameNode contains the files  \n",
    "Files break down into blocks  \n",
    "Blocks are duplictaed 3 times and go into the DataNodes  \n",
    "A Java Virtual Machine is required to process a block  \n",
    "$\\quad$ if we have too many blocks, scalability is limited\n",
    "\n",
    "**More detailed look of ^**  \n",
    "Files are broken into blocks and then duplicated 3 times  \n",
    "$\\quad$ Typical HDFS block = 128 mb (128000 kb)  \n",
    "$\\quad$ Typical windows block = 4 kb    \n",
    "\n",
    "Each cluster runs as master/slave  \n",
    "Master = NameNode (1 or 2) - keeps track of files, blocks, DataNodes  \n",
    "$\\quad$ NameNodes store this info in memory (rule of thumb - each block takes 150 bytes of memory)  \n",
    "Slave = DataNodes (many) - read and write the actual data\n",
    "\n",
    "#### Copying Info \n",
    "\n",
    "`hadoop fs -put file.txt /reports` local -> hdfs  \n",
    "`hadoop fs -get /reports/file.txt` hdfs -> local\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### LAB\n",
    "Lab -https://github.umn.edu/deliu/bigdata19/blob/master/02-Hadoop/lab01-hdfs.md  \n",
    "Solution - https://pages.github.umn.edu/deliu/bigdata19/02-Hadoop/lab01-hdfs-solution.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List contents of hdfs root directory  \n",
    "`hadoop fs -ls /dualcore`\n",
    "\n",
    "Remove directories  \n",
    "`hadoop fs -rm -r /dualcore\n",
    "hadoop fs -rm -r weblog\n",
    "hadoop fs -rm -r testlog`\n",
    "\n",
    "create a `/dualcore` directory  \n",
    "`hadoop fs -mkdir /dualcore`\n",
    "\n",
    "---\n",
    "\n",
    "### From local --> hdfs  \n",
    "Take a web server log file from our course materials folder into dualcore  \n",
    "`hadoop fs -put ADIR/data/access.log /dualcore`\n",
    "\n",
    "Deleting a file  \n",
    "`hadoop fs -rm /dualcore/access.log`\n",
    "\n",
    "---\n",
    "\n",
    "### Take compressed web file, send to hdfs (skips the local part)\n",
    "\n",
    "Make directory in hdfs  \n",
    "`hadoop fs -mkdir weblog`\n",
    "\n",
    "unzip and upload access_log.gz  \n",
    "`gunzip -c ~/training_materials/developer/data/access_log.gz | hadoop fs -put - weblog/access_log`  \n",
    "`-c` to uncompress  \n",
    "`-` after put is to send the directory\n",
    "\n",
    "Save first 5000 rows  \n",
    "`hadoop fs -mkdir testlog\n",
    "gunzip  -c ~/training_materials/developer/data/access_log.gz \\\n",
    "| head -n 5000 | \\\n",
    "hadoop fs -put - testlog/test_access_log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### B. HDFS Commands\n",
    "\n",
    "**Before we begin - remove destination directories**  \n",
    "`hadoop fs -rm -r /latlon`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12\\. Create a folder `latlon` in HDFS\n",
    "\n",
    "`hadoop fs -mkdir /latlon`\n",
    "\n",
    "---\n",
    "\n",
    "### Local --> hdfs\n",
    "\n",
    "13\\. Navigate to `$ADIR/data` in the local machine, and put a sample of `latlon.tsv` (first 1000 rows) into latlon \n",
    "\n",
    "\n",
    "`cd` \\$`ADIR/data/latlon.tsv`   \n",
    "`head -n 1000 latlon.tsv` | `hadoop fs -put - latlon/latlon.tsv` `\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "14\\. List the content of the `latlon` folder in HDFS\n",
    "\n",
    "`hadoop fs -ls /latlon`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "15\\. Display the first 10 rows of the `latlon.tsv` in HDFS.\n",
    "\n",
    "`hadoop fs -cat latlon/latlon.tsv | head -n 10`\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "16\\. Replace the `latlon.tsv` in HDFS with the full file\n",
    "\n",
    "`hadoop fs -rm latlon/latlon.tsv` to remove the old  \n",
    "`hadoop fs -put latlon.tsv latlon/latlon.tsv` to add the new\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### HDFS --> Local\n",
    "\n",
    "17\\. Download `latlon.tsv` from HDFS as `latlon_hdfs.tsv` in the local folder `ADIR/data` \n",
    "\n",
    "\n",
    "`hadoop fs -get /latlon/latlon.tsv latlon_hdfs.tsv`\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "18\\. Make a copy of `latlon.tsv` in HDFS and name it `latlon2.tsv` (in the same HDFS folder). \n",
    "\n",
    "`hadoop fs cp /latlon/latlon.tsv /latlon/latlon2.tsv`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "19\\. Download the entire content of the latlon folder in HDFS as a single local file.  \n",
    "Call the file `latlon_all_hdfs.tsv` and place in the folder ADIR/data\n",
    "\n",
    "\n",
    "`hadoop fs -getmerge latlon/* latlon_all_hdfs.tsv`\n",
    "\n",
    "---\n",
    "20\\. Remove the folder `latlon` on HDFS \n",
    "\n",
    "`hadoop fs -rm -r /latlon`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# MapReduce\n",
    "`processing`\n",
    "\n",
    "\n",
    "<img src=https://i.imgur.com/JcxE2Sa.jpg width=\"400\" height=\"340\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "MapReduce is a programming model, typically uses Java (also supports Python)  \n",
    "Follows the \"shared-nothing\" architecture - tasks are not dependent on each other\n",
    "\n",
    "**2 functions, both written by the user**  \n",
    "Map - takes input pair, produces set of intermediate pairs, then groups values that have the same key and pass to reduce  \n",
    "$\\quad$ The value is a row from the input  \n",
    "Reduce - accepts intermediate key + values, shuffle and sort, merges values together  \n",
    "$\\quad$ The values a collection of all values for each key\n",
    "\n",
    "**Example**  \n",
    "`Input` - Take input of url and page  \n",
    "`Map output` Key = url, Value = series of key value pairs. Ultimately value is a  pair of key=term, value=frequency  \n",
    "`Reduce output` Key = url, Value = term freq pairs compressed into one\n",
    "\n",
    "\n",
    "#### Benefits of MapReduce\n",
    "\n",
    "1. Simple compared to other distributed programming models  \n",
    "2. Flexible - handles data like images, video, etc  \n",
    "3. Scalable - able to finish sooner by adding more workers\n",
    "\n",
    "Quickly losing ground to Spark and other engines\n",
    "\n",
    "\n",
    "**debugging before running thru mapreduce**  \n",
    "`hadoop fs -cat /dualcore/employees/* \\\n",
    "| head -n 100 \\\n",
    "| python mapper.py \\\n",
    "| sort \\\n",
    "| python reducer.py`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Lab 2 - MapReduce\n",
    "\n",
    "https://pages.github.umn.edu/deliu/bigdata19/02-Hadoop/lab02-mapreduce.html  \n",
    "https://pages.github.umn.edu/deliu/bigdata19/02-Hadoop/lab02-mapreduce-solution.html\n",
    "\n",
    "\n",
    "for each state, how many employees earn > 75k?\n",
    "\n",
    "**Step 1 - enter the directory**  \n",
    "`cd ADIR/exercises/data_ingest/bonus_01`  \n",
    "`ls -l` to see the files\n",
    "\n",
    "**Step 2 - clean output destination**  \n",
    "`rm results.txt\n",
    "hadoop fs -rm -r /user/cloudera/empcounts`\n",
    "\n",
    "\n",
    "**Step 3 - view mapper, reducer, and runjob shell script**  \n",
    "`cat mapper.py\n",
    "cat reducer.py\n",
    "cat runjob.sh`\n",
    "\n",
    "\n",
    "**Step 4 - verify results**  \n",
    "`hadoop fs -ls /user/cloudera/empcounts` does this directory already exist?  \n",
    "`hadoop fs -cat input_data | head -n 100 | python mapper.py | sort | python reducer.py` to debug  \n",
    "`./runjob.sh` **to run the job**  \n",
    "`hadoop fs -getmerge /user/cloudera/empcounts results.txt` to download the results to a local file  \n",
    "`less results.txt` to view results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Pair RDDs\n",
    "\n",
    "[Full Slides](https://pages.github.umn.edu/deliu/bigdata19/13-PairRDD/Spark4-PairRDDs.pdf)\n",
    "\n",
    "Why?  \n",
    "- Better for joining/sort/count/ other aggregation stuff\n",
    "- Faster (using mapreduce -- map each record to one or more records, reduce by agg)\n",
    "\n",
    "`Pair RDDs is how Spark implements MapReduce`\n",
    "\n",
    "<img src=https://i.imgur.com/RfclYM0.png width=\"400\" height=\"340\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create pairs\n",
    "\n",
    "[Create Pairs Slides](file:///C:/Users/Sam/Desktop/Big%20Data/Hive/create%20pairs.pdf)  \n",
    "https://www.youtube.com/watch?v=eOKeIUE5S1w\n",
    "\n",
    "\n",
    "**Pair RDD - key value pairs**  \n",
    "What should the keys/values be?  \n",
    "\n",
    "- `map` and `flatMap` same as before\n",
    "\n",
    "\n",
    "- `flatMapValues` keep the keys, just map values  \n",
    "`users = sc.textFile(file) \\\n",
    ".map(lambda line: line.split('\\t')) \\\n",
    ".map(lambda fields: (fields[0],fields[1]))`\n",
    "\n",
    "\n",
    "- `keyBy` keep the values, just add keys  \n",
    "`sc.textFile(logfile) \\\n",
    ".keyBy(lambda line: line.split(' ')[2])`\n",
    "\n",
    "\n",
    "- complex values  \n",
    "`sc.textFile(file) \\\n",
    ".map(lambda line: line.split('\\t')) \\\n",
    ".map(lambda fields: (fields[0],(fields[1],fields[2])))`\n",
    "\n",
    "\n",
    "- map single values to multiple pairs  \n",
    "`sc.textFile(file) \\\n",
    ".map(lambda line: line.split('\\t')) \\\n",
    ".map(lambda fields: (fields[0],fields[1]))\n",
    ".flatMapValues(lambda skus: skus.split(':'))`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Pair RDD operations\n",
    "\n",
    "[Examples in Slides](file:///C:/Users/Sam/Desktop/Big%20Data/Hive/pair%20ops.pdf)  \n",
    "https://www.youtube.com/watch?v=6CzJfrz3yJk\n",
    "\n",
    "- `reduceByKey` (trans) merge values per key  \n",
    "\n",
    "- `countByKey` (act) count elements per key\n",
    "\n",
    "- `groupByKey` (trans) single sequence per group\n",
    "\n",
    "- `sortByKey` (trans)\n",
    "\n",
    "- `join` (trans) return rdd containing all pairs with matching keys\n",
    "\n",
    "---\n",
    "\n",
    "**Word counts example**  \n",
    "`counts = sc.textFile(file) \\\n",
    ".flatMap(lambda line: line.split()) \\` to get the list of words  \n",
    "`.map(lambda word: (word,1)) \\` to initialize the count  \n",
    "`.reduceByKey(lambda v1,v2: v1+v2)` to add up the counts per word\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Other pair operations\n",
    "\n",
    "[Slides](file:///C:/Users/Sam/Desktop/Big%20Data/Hive/Arc.pdf)  \n",
    "https://www.youtube.com/watch?v=jArlIctlb7w\n",
    "\n",
    "- `keys` - return rdd of keys\n",
    "- `values` - return rdd of values\n",
    "- `lookup(key)` - return value for key\n",
    "- `leftOuterJoin` - include keys from left\n",
    "- `mapValues, flatMapValues` - ignore the keys, operate on values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

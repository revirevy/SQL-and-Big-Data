{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark RDD\n",
    "\n",
    "[RDD Documentation](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "\n",
    "**Deployment models**  \n",
    "Local mode - `JVM` (Java virtual machine)  \n",
    "Cluster mode - `yarn`, `Standalone`, `Mesos`\n",
    "\n",
    "**Spark Clusters**  \n",
    "Driver program uses SparkContext to communicate with cluster manager. Cluster manager splits RDDs by nodes.  \n",
    "Driver program = who we write our commands to.  \n",
    "SparkConext = stores info about location of cluster or APIs. creates RDDs. specifies which cluster resource to use. \n",
    "\n",
    "**Partitions** ~128/partition  \n",
    "RDD will be split into partitions  \n",
    "Each node can work on one partition per time\n",
    "\n",
    "**Opening jupyter**  \n",
    "Run `pyspark`  \n",
    "Copy and paste url  \n",
    "Change to `localhost`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### RDD\n",
    "\n",
    "[RDD Slides](file:///C:/Users/Sam/Desktop/Big%20Data/Spark/RDD.pdf)\n",
    "\n",
    "Unstuctured - no schema, just collection of elements  \n",
    "Often used to convert unstructured into structured  \n",
    "Works with normal, complex, double, pairs\n",
    "\n",
    "RDD is loaded into a cluster into the cluster's memory\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Creating RDD\n",
    "\n",
    "[Slides](file:///C:/Users/Sam/Desktop/Big%20Data/Spark/Creating%20rdd.pdf)\n",
    "\n",
    "**Ways to create**  \n",
    "1\\. From stored files - uses lazy loading  \n",
    "`parellelize`, `sc.textFile`, `sc.wholeTextFile`, `sc.hadoopFile`, `sc.newAPIHadoopFile`  \n",
    "2\\. Transforming an existing rdd  \n",
    "3\\. Using programs to parellelize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[Trans vs Acts Slides](file:///C:/Users/Sam/Desktop/Big%20Data/Hive/Transandact.pdf)\n",
    "\n",
    "### Transformations (lazy)\n",
    "\n",
    "[Transformations Slides](file:///C:/Users/Sam/Desktop/Big%20Data/Hive/Trams.pdf)  \n",
    "https://www.youtube.com/watch?v=SVw1gbinUBc\n",
    "\n",
    "**Generates new RDDs based on the current one**  \n",
    "**Happens in distributed fashion**  \n",
    "\n",
    "<img src=https://i.imgur.com/9PRtvSZ.png width=\"350\" height=\"300\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Actions (not lazy)\n",
    "\n",
    "[Actions Slides](file:///C:/Users/Sam/Desktop/Big%20Data/Hive/acts.pdf)  \n",
    "https://www.youtube.com/watch?v=XnNStkSA-X0\n",
    "\n",
    "**Returns a local dataset (non-RDD)**  \n",
    "\n",
    "**Actions work in pairs (lambda functions)**  \n",
    "`Associative` - applies to all elements in list  \n",
    "`Communatitive` - order doesn't matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Cache and Demo\n",
    "\n",
    "[Lazy Ex / Caching Slides](file:///C:/Users/Sam/Desktop/Big%20Data/Hive/lazy.pdf)  \n",
    "https://www.youtube.com/watch?v=xMT3vzpdcFU\n",
    "\n",
    "**So that Spark doesn't restart everything when we run a different transformation**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Transformation + actions demo\n",
    "\n",
    "**See 5 distinct words per line** - Flatmap, distinct  \n",
    "`sc.textFile(file) \\ \n",
    ".flatMap(lambda line: line.split()) \\\n",
    ".distinct().take(5)`\n",
    "\n",
    "**Transformations**  \n",
    "`rdd.map(lambda function)`  \n",
    "`rdd.filter(lambda function)`  \n",
    "`rdd.distinct()`\n",
    "\n",
    "**Actions**  \n",
    "`rdd.reduce(lambda function)`  \n",
    "`rdd.take(5)`  \n",
    "`rdd.collect()`  \n",
    "\n",
    "**Action - take values, ordered**  \n",
    "`rdd.takeOrdered(3, lambda s: -1 * s)`\n",
    "\n",
    "**Other operations**  \n",
    "<img src=https://i.imgur.com/IJCYyvg.png width=\"350\" height=\"300\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

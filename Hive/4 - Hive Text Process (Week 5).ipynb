{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Text Analytics (Hive)\n",
    "# Part 2 - Log Data (Hive)\n",
    "# Part 3 - Extending Hive\n",
    "\n",
    "Sept 30 - lab 10  \n",
    "Oct 2 - lab 11\n",
    "\n",
    "<a href=\"#String-Functions\">Strings</a>  \n",
    "<a href=\"#Regular-Expressions\">Regex</a>  \n",
    "<a href=\"#Extending-Hive-(JSON,-Custom-Scripts,-and-UDFs)\">Extending Hive</a>  \n",
    "<a href=\"#Optimizing-Hive-Query-Performance\">Optimize</a>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# String Functions\n",
    "\n",
    "[Regex Cheat Sheet](https://pages.github.umn.edu/deliu/bigdata19/05-Hive3/regular-expressions-cheat-sheet-v2.pdf)\n",
    "\n",
    "**Essential points**  \n",
    "`Split` creates an array from a string  \n",
    "`Explode` creates indy records from an array  \n",
    "`Regex` to extract or sub strings  \n",
    "`N-grams` is a sequence of words\n",
    "\n",
    "(inclusive, exclusive)\n",
    "\n",
    "Splitting converts to an array  \n",
    "Use `SELECT EXPLODE(SPLIT(..)` instead\n",
    "Insert image (splitting and combining) \n",
    "\n",
    "Create histogram with 10 bins (we could also use subq instead)  \n",
    "`from products\n",
    "select explode(histogram_numeric(price,10)) as bin`\n",
    "\n",
    "\n",
    "``histogram_numeric(id, 5) from customers`  \n",
    "returns one single row - an array of struct\n",
    "\n",
    "---\n",
    "\n",
    "<img src=https://i.imgur.com/0uRU4rR.png width=\"400\" height=\"340\" align=\"left\">\n",
    "\n",
    "\n",
    "<img src=https://i.imgur.com/n7gQtlS.png width=\"400\" height=\"340\" align=\"left\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://i.imgur.com/Ptd8sxp.png width=\"400\" height=\"340\" align=\"left\">\n",
    "\n",
    "\n",
    "<img src=https://i.imgur.com/kkSPzam.jpg width=\"400\" height=\"340\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Regular Expressions\n",
    "\n",
    "**Regex classes** - character, white space, word  \n",
    "Use `()` to capture something  \n",
    "`\\\\` because 2 interpreters (Hive, then regex engine)\n",
    "\n",
    "`[]` list of options  \n",
    "`^` is negate  \n",
    "`\\\\d` is digit  \n",
    "`+` adds one or more  \n",
    "`.` any character (unless we are inside [])\n",
    "\n",
    "\n",
    "**Hive's reg expressions**  \n",
    "`REGEXP` for comparison  \n",
    "`REGEXP_EXTRACT` to return string matching a patter  \n",
    "`REGEXP_REPLACE` to replace text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=https://i.imgur.com/D31V71F.png width=\"400\" height=\"340\" align=\"left\">\n",
    "\n",
    "<img src=https://i.imgur.com/7YZz4nh.png width=\"400\" height=\"340\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### CSV SerDa (when too complex for SerDa)\n",
    "\n",
    "**Hive built in Serdes** - specify when creating table in **row format**  \n",
    "`\n",
    "LazySimpleSerDe (default)\n",
    "RegexSerDe - use for semi structured data, especially for log files\n",
    "OpenCSVSerde\n",
    "JsonSerDe\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sentiment Analysis\n",
    "\n",
    "1 - Tokenize the text with `SENTENCE(input)`  \n",
    "Outer array - each sentence  \n",
    "Inner array - each word in each sentence\n",
    "\n",
    "2 - Find n-grams with `NGRAMS(array, number of words per ngram, threshold for result)`  \n",
    "Output is a struct with 2 attributes - ngram, estfrequency  \n",
    "Can also use `context_ngrams` if we want certain combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending Hive (JSON, Custom Scripts, and UDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON\n",
    "\n",
    "Use jsonserde when each line of the document is a JSON object \n",
    "\n",
    "Supports arrays and maps, nested structures  \n",
    "Have to load JSON with a special Serde\n",
    "\n",
    "---\n",
    "\n",
    "### json file with 3 \"topics\"\n",
    "\n",
    "Create a table and load in as 1 field  \n",
    "`create table raw\n",
    "(json string)\n",
    "row format delimited;`\n",
    "\n",
    "For each table:  \n",
    "`insert into users\n",
    "select * from raw\n",
    "get_json_object(...)` \n",
    "\n",
    "Could also use **hadoop streaming** with python scripts to extract users, reviews, businesses.  \n",
    "This would be 3 separate mapreduce jobs.\n",
    "\n",
    "---\n",
    "\n",
    "### Querying json fields (non json tables)\n",
    "\n",
    "#### Dictionary example \n",
    "Can use the \"value\" as a list of strings and use `get_json_object` to parse field.  \n",
    "This is different than a complex field.  \n",
    "`input` should be a string with a JSON format. \n",
    "\n",
    "\n",
    "$: root object  \n",
    "`[ ]`: subscript operator for array  \n",
    "`.` : child operator\n",
    "\n",
    "`get_json_object(input,` $`.parent.child[index])`\n",
    "\n",
    "---\n",
    "\n",
    "### Use external script to transform data\n",
    "\n",
    "`*` = fields to transform  \n",
    "`hive> ADD FILE myscript.py;\n",
    "hive> SELECT TRANSFORM(*) USING 'myscript.py' FROM employees;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example with only 2 fields**  \n",
    "`hive> SELECT TRANSFORM(product_name, price)\n",
    "USING 'tax_calculator.py'\n",
    "AS (item_name STRING, tax INT)\n",
    "FROM products;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### User defined functions\n",
    "\n",
    "1. Standard udf - normal function, single row input, single row output\n",
    "2. user defined aggregate functions - (sum, max, etc)\n",
    "3. user defined table functions (explode, etc)\n",
    "\n",
    "**To use a java udf**  \n",
    "1. Copy function's jar into hdfs  \n",
    "`hadoop fs -put url-decode-udf.jar /myscripts/` \n",
    "\n",
    "2. Register the function  \n",
    "`CREATE FUNCTION url_decode\n",
    "AS 'com.example.hive.udf.URLDecode'\n",
    "USING JAR '/myscripts/url-decode-udf.jar';`\n",
    "\n",
    "3. Use the function  \n",
    "`select url_decode(your_url);`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 (Sept 30) - Text Analytics with Hive\n",
    "\n",
    "[Lab](https://pages.github.umn.edu/deliu/bigdata19/05-Hive3/lab10-text.html)  \n",
    "[Solution](https://pages.github.umn.edu/deliu/bigdata19/05-Hive3/lab10-text-solution.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Customers not have with prod_id = 1274673  \n",
    "Although numeric ratings can help identify which product that is, they don’t tell us why customers don’t like the product. \n",
    "\n",
    "Normalizes all comments on that product to lowercase,  \n",
    "breaks them into individual words using the SENTENCES function,  \n",
    "passes those to the NGRAMS function to find combos  \n",
    "use EXPLODE to break up ngrams outcomes into separate rows.\n",
    "\n",
    "Notes  \n",
    "Should remove `stop words` (ie need to filter out) by replacing with null  \n",
    "`ngrams` returns complex field (array of values)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### RUNNING NGRAMS QUERY \n",
    "\n",
    "**Trigrams, Top 5**  \n",
    "`SELECT EXPLODE(NGRAMS(SENTENCES(LOWER(message)), 3, 5))\n",
    "AS bigrams\n",
    "FROM ratings\n",
    "WHERE prod_id = 1274673;`\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Investigating after query\n",
    "\n",
    "**Pattern identified from trigrams**  \n",
    "`SELECT message\n",
    "FROM ratings\n",
    "WHERE prod_id = 1274673\n",
    "AND message LIKE '%ten times more%'\n",
    "LIMIT 3;`\n",
    "\n",
    "**\"Red was a word that popped up. Why?**  \n",
    "**All messages that have \"red\"**  \n",
    "`SELECT message\n",
    "FROM ratings\n",
    "WHERE prod_id = 1274673\n",
    "AND message LIKE '%red%'\n",
    "LIMIT 3;`\n",
    "\n",
    "---\n",
    "\n",
    "**There must be a pricing error.**  \n",
    "**Check in the products table**  \n",
    "`SELECT *\n",
    "FROM products\n",
    "WHERE prod_id = 1274673;`\n",
    "\n",
    "**Compare red product vs same product of diff colors**  \n",
    "`SELECT *\n",
    "FROM products\n",
    "WHERE name LIKE '%16 GB USB Flash Drive%'\n",
    "AND brand='Orion';`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11 (Oct 2) - Log Data\n",
    "\n",
    "\n",
    "[Lab](https://pages.github.umn.edu/deliu/bigdata19/05-Hive3/lab11-weblog.html)  \n",
    "[Solution](https://pages.github.umn.edu/deliu/bigdata19/05-Hive3/lab11-weblog-solution.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Directory for exercise  \n",
    "`cd ADIR/exercises/transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how Hive would set up the table - helps us set types and Serde  \n",
    "create_web_logs.hql is a script that already exists  \n",
    "`beeline -u jdbc:hive2:// -f create_web_logs.hql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Local --> HDFS\n",
    "\n",
    "Make directory in hdfs  \n",
    "`hadoop fs -mkdir /dualcore/web_logs`\n",
    "\n",
    "Take file from exercises folder into hdfs (dualcore folder)  \n",
    "`hadoop fs -put ADIR/data/access.log /dualcore/web_logs`\n",
    "\n",
    "Supposed to run this command to make sure everything worked correctly  \n",
    "`SELECT term, COUNT(term) AS num FROM\n",
    "     (SELECT LOWER(REGEXP_EXTRACT(request,\n",
    "        '/search\\\\?phrase=(\\\\S+)', 1)) AS term\n",
    "        FROM web_logs\n",
    "        WHERE request REGEXP '/search\\\\?phrase=') terms\n",
    "   GROUP BY term\n",
    "   ORDER BY num DESC\n",
    "   LIMIT 3;`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 2 - Identify steps in process\n",
    "\n",
    "There are 4 steps. We want to count how many people made it to each step.  \n",
    "\n",
    " `SELECT COUNT(*), request\n",
    " FROM web_logs\n",
    " WHERE request REGEXP '/cart/checkout/step\\\\d.+'\n",
    " GROUP BY request;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Who is making it to which step in the process?  \n",
    "Create a table to show this.\n",
    "\n",
    "` CREATE TABLE checkout_sessions AS\n",
    " SELECT cookie, ip_address, COUNT(request) AS steps_completed\n",
    " FROM web_logs\n",
    " WHERE request REGEXP '/cart/checkout/step\\\\d.+'\n",
    " GROUP BY cookie, ip_address;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12 (Oct 2) - JSON\n",
    "\n",
    "[Lab](https://pages.github.umn.edu/deliu/bigdata19/05-Hive3/lab12-extension.html)  \n",
    "[Solution](https://pages.github.umn.edu/deliu/bigdata19/05-Hive3/lab12-extension-solution.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an external table\n",
    "\n",
    "This is an external table so we need to specify where we are going to save the table  \n",
    "`CREATE EXTERNAL TABLE json_nested_test (\n",
    "country string,\n",
    "languages array<string>,\n",
    "religions map<string,array<int>>)\n",
    "ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '...';`  \n",
    "In hive 4.0, we can use `stored as jsonfile`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 - get_json_object\n",
    "\n",
    "Remember: \\$.parent.child  \n",
    "\n",
    "**Price of bicycle**  \n",
    "In this example, the word 'price' is a key. The actual price is the associated value\n",
    "\n",
    "`select get_json_object(\n",
    "'{\"store\": \n",
    "    {\"fruit\":[{\"weight\":8,\"type\":\"apple\"},{\"weight\":9,\"type\":\"pear\"}],\n",
    "    \"bicycle\":{\"price\":19.95,\"color\":\"red\"}}, \n",
    "\"email\":\"amy@only_for_json_udf_test.net\", \n",
    "\"owner\":\"amy\"}'`  \n",
    ",'$`.store.bicycle.price');`\n",
    "\n",
    "---\n",
    "\n",
    "**name of the first fruit**  \n",
    "In this example, \"fruit\" is a list.  \n",
    "\"Type\" is a key that has the \"name\" of the fruit as the value\n",
    "\n",
    "`select get_json_object(\n",
    "'{\"store\": \n",
    "    {\"fruit\":[{\"weight\":8,\"type\":\"apple\"},{\"weight\":9,\"type\":\"pear\"}],\n",
    "    \"bicycle\":{\"price\":19.95,\"color\":\"red\"}}, \n",
    "\"email\":\"amy@only_for_json_udf_test.net\", \n",
    "\"owner\":\"amy\"}'`  \n",
    ",'$`.store.fruit[0].type');`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 - JSON tables\n",
    "\n",
    "**Download the JSON serde jar file to your home directory**\n",
    "\n",
    "`cd ~`  \n",
    "`wget http://idsdl.csom.umn.edu/c/share/msba6330/json-serde-1.3.8-jar-with-dependencies.jar` to download jar  \n",
    "`ADD JAR /home/cloudera/json-serde-1.3.8-jar-with-dependencies.jar;` to add a jar\n",
    "\n",
    "**Extract a sample row**  \n",
    "`cd ~/training_materials/data/chatlogs\n",
    "head -1 2014-03-15.json`\n",
    "\n",
    "**Create a hive managed table**  \n",
    "`create table conversations (\n",
    "\tconversationId INT,\n",
    "\taccountNum INT,\n",
    "\tagentName STRING,\n",
    "\tcategory STRING,\n",
    "\tmessages ARRAY<STRUCT<sender:STRING, time:TIMESTAMP, text:STRING>>\n",
    ") \n",
    "ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe';`\n",
    "\n",
    "**Load local file into managed table**  \n",
    "`load data local inpath '/home/cloudera/training_materials/data/chatlogs/2014-03-15.json' \n",
    "into table conversations;`\n",
    "\n",
    "**Check**  \n",
    "`select count(*) from conversations;` number of rows  \n",
    "`select * from conversations limit 2;` first 2 rows  \n",
    "`select conversationid, size(messages) from conversations limit 10;` first rows with additional info (size = size of array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3 - Transforming\n",
    "\n",
    "**Download a python script**  \n",
    "`wget http://idsdl.csom.umn.edu/c/share/msba6330/greeting.py`\n",
    "\n",
    "**Upload to hdfs**  \n",
    "`hadoop fs -put greeting.py greeting.py`\n",
    "\n",
    "**Create a table in hue**  \n",
    "`create table employees (name string, email string)\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';`\n",
    "\n",
    "**Insert values into table**  \n",
    "`INSERT INTO table employees \n",
    "values \n",
    "(\"Antoine\",\"antoine@example.fr\"),\n",
    "(\"Kai\",\"kai@example.de\"),\n",
    "(\"Pedro\",\"pedro@example.mx\"),\n",
    "(\"Joel\",\"joel@example.us\");`\n",
    "\n",
    "**Add and run the transformation file**  \n",
    "`add file hdfs:///user/cloudera/greeting.py;`\n",
    "\n",
    "`SELECT TRANSFORM(name,  email)\n",
    "    USING 'greeting.py' AS greeting\n",
    "    FROM employees;`\n",
    "    \n",
    "---\n",
    "\n",
    "**This is what the python script looked like**  \n",
    "`import sys\n",
    "import re\n",
    "greetings  = {'de':'Hallo','fr':'Bonjour','mx':'Hola'}`\n",
    "\n",
    "`for line in sys.stdin:\n",
    "    name, email = line.strip().split('\\t')\n",
    "    match = re.search(r'\\.(\\w+)', email)\n",
    "    if match and greetings.has_key(match.group(1)):\n",
    "        print \"{0}\\t{1}\".format(greetings[match.group(1)],name)\n",
    "    else:\n",
    "        print \"Hello\\t{0}\".format(name)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a table\n",
    "`hive> CREATE {DATABASE|SCHEMA} dualcore;`\n",
    "\n",
    "##### External and textfile\n",
    "` CREATE EXTERNAL TABLE employees\n",
    "    (emp_id STRING,\n",
    "     fname STRING,\n",
    "     salary INT)  \n",
    "    ROW FORMAT DELIMITED  \n",
    "       FIELDS TERMINATED BY '\\t'  \n",
    "       LOCATION '/dualcore/employees';`\n",
    "       \n",
    "##### Internal and non-textfile\n",
    "       \n",
    "` CREATE TABLE employees\n",
    "    (emp_id STRING,\n",
    "     fname STRING,\n",
    "     salary INT)  \n",
    "    ROW FORMAT serde serde_name WITH PROPERTIES (specs);`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Loading in data\n",
    "\n",
    "Hadoop way - `hadoop fs -mv sales.txt /user/hive/warehouse/sales/`  \n",
    "Hive way (from hdfs) - `hive> LOAD DATA INPATH 'sales.txt' INTO TABLE sales;`\n",
    "\n",
    "### From hdfs to hive\n",
    "\n",
    "`hadoop fs -mv filename.txt /directory/directory/sales/`  \n",
    "(within hive) `load data inpath \"filename.txt\" into table sales;`\n",
    "\n",
    "---\n",
    "\n",
    "### From local drive\n",
    "\n",
    "Hadoop way - `hadoop fs -put /home/sales.txt /user/hive/warehouse/sales/`  \n",
    "(within hive) `load data local inpath \"/path/to/filename.txt\" into table sales;`\n",
    "\n",
    "---\n",
    "\n",
    "##### Load data from files (overwriting current records)\n",
    "Hive way (from hdfs) - `hive> LOAD DATA INPATH 'dept/finance' OVERWRITE INTO TABLE sales;`\n",
    "\n",
    "##### Load data from RDBMS (using sqoop here)\n",
    "\n",
    "` sqoop import \\\n",
    " --connect jdbc:mysql://localhost/dualcore \\\n",
    " --username root --password cloudera \\\n",
    " --fields-terminated-by '\\t' \\\n",
    " --hive-table dualcore.suppliers \\\n",
    " --table suppliers \\\n",
    " --hive-import`\n",
    " \n",
    "---\n",
    "\n",
    "### Create table using query from another table\n",
    "\n",
    "`create table good_customers as\n",
    "    select col1, col2 from customers\n",
    "    where status = 'good';`\n",
    "    \n",
    "### Saving data from hive\n",
    "\n",
    "##### to hdfs\n",
    "\n",
    "`INSERT OVERWRITE DIRECTORY 'path/to/hdfs/directory'\n",
    "    select col1, col2 from customers\n",
    "    where status = 'good';`\n",
    "\n",
    "##### to local\n",
    "\n",
    "`INSERT OVERWRITE local DIRECTORY 'path/to/local/directory'\n",
    "    select col1, col2 from customers\n",
    "    where status = 'good';`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
